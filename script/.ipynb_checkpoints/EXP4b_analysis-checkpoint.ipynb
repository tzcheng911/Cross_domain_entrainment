{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "- Import the package\n",
    "- Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics # confusion matrix, MSE etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/Users/t.z.cheng/Google_Drive/Research/Delaydoesmatter/real_exp/exp4_20CR12/results_shortlongdelay_2021/v2_20CR12_clean_n67.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the data\n",
    "df = pd.read_csv(path_to_data)\n",
    "# df_clean = df\n",
    "## Take a look of the dataset\n",
    "# df.head()\n",
    "# df.tail()\n",
    "# df.loc[558:663] # see specific rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up task and subject ID (first five characters)\n",
    "df['task'] = df['trial_template'].apply(lambda x: x.split(\"_\")[0])\n",
    "df['sub_id'] = df['participant_id'].apply(lambda x: x.split()[0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the accuracy and PPS column to the dataset: transform True and Shorter to 1, False and longer to 0\n",
    "Correct = []\n",
    "Shorter = []\n",
    "for i in np.arange(0,len(df)):\n",
    "    if df['response_correct'][i] == True:\n",
    "        Correct.append(1)\n",
    "    else: \n",
    "        Correct.append(0)\n",
    "    if df['response_value'][i] == \"Shorter\":\n",
    "        Shorter.append(1)\n",
    "    else: \n",
    "        Shorter.append(0)\n",
    "df['Correct'] = Correct\n",
    "df['Shorter'] = Shorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt = df[['participant_id','group_id']].drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = df_Accuracy.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_acc,attempt,on = 'participant_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['participant_id','group_id']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters\n",
    "- Accuracy threshold for the easiest trials of the main task \n",
    "- Extreme RT threshold\n",
    "- Catch trial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "threshold = .55\n",
    "catch_threshold = .8\n",
    "RT_threshold = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning \n",
    "***Super important: df_clean is overwritten after each step of data cleaning***\n",
    "\n",
    "**Reject subjects**\n",
    "- Practice accuracy in conditional branching block\n",
    "- Catch trial\n",
    "- Environmental noise & audio device (may not need to use them as criteria)\n",
    "\n",
    "**Reject trials**\n",
    "- Task-relevant trials\n",
    "- Extreme RT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reject subjects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many subjects miss the catch trial \n",
    "catch_trials = ['Catch_beat','Catch_bag']\n",
    "df_catch = df[(df['trial_template'].isin(catch_trials))].reset_index(drop = True) # reset index from 1\n",
    "catch_acc = df_catch.groupby('sub_id')['response_correct'].sum()/df_catch.groupby('participant_id')['response_correct'].count()\n",
    "catch_acc[catch_acc < catch_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many subjects pass the practice > 0.75 on the easiest ontime trials \n",
    "df_clean = df[df['branch_failpass'] == 'pass'].reset_index(drop = True)\n",
    "print('How many subjects passed the practice trials:', len(df_clean['sub_id'].unique())\n",
    "      ,'out of',len(df['sub_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## How many subjects had a bad environmental noise and device\n",
    "df_noise = df[(df['response_name'] == 'survey_noise')].reset_index(drop = True)\n",
    "noise = df_noise.groupby('sub_id')['response_value'].sum()\n",
    "df_device = df[(df['response_name'] == 'survey_headphone')].reset_index(drop = True)\n",
    "df_device[['sub_id','response_value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task relevant trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subj id\n",
    "subID = df['sub_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All condition\n",
    "conds = ['single_300ms_delay_2_51','single_300ms_delay_2_52','single_300ms_delay_2_53','single_300ms_delay_2_54','single_300ms_delay_2_55','single_300ms_delay_2_56',\n",
    "        'single_300ms_delay_2_81','single_300ms_delay_2_82','single_300ms_delay_2_83','single_300ms_delay_2_84','single_300ms_delay_2_85','single_300ms_delay_2_86',\n",
    "        'single_300ms_delay_2_91','single_300ms_delay_2_92','single_300ms_delay_2_93','single_300ms_delay_2_94','single_300ms_delay_2_95','single_300ms_delay_2_96',\n",
    "        'single_300ms_delay_4_51','single_300ms_delay_4_52','single_300ms_delay_4_53','single_300ms_delay_4_54','single_300ms_delay_4_55','single_300ms_delay_4_56',\n",
    "        'single_300ms_delay_4_81','single_300ms_delay_4_82','single_300ms_delay_4_83','single_300ms_delay_4_84','single_300ms_delay_4_85','single_300ms_delay_4_86',\n",
    "        'single_300ms_delay_4_91','single_300ms_delay_4_92','single_300ms_delay_4_93','single_300ms_delay_4_94','single_300ms_delay_4_95','single_300ms_delay_4_96']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conditions short\n",
    "conds = ['single_300ms_delay_2_51','single_300ms_delay_2_52','single_300ms_delay_2_53','single_300ms_delay_2_54','single_300ms_delay_2_55','single_300ms_delay_2_56',\n",
    "        'single_300ms_delay_2_81','single_300ms_delay_2_82','single_300ms_delay_2_83','single_300ms_delay_2_84','single_300ms_delay_2_85','single_300ms_delay_2_86',\n",
    "        'single_300ms_delay_2_91','single_300ms_delay_2_92','single_300ms_delay_2_93','single_300ms_delay_2_94','single_300ms_delay_2_95','single_300ms_delay_2_96']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conditions long\n",
    "conds = ['single_300ms_delay_4_51','single_300ms_delay_4_52','single_300ms_delay_4_53','single_300ms_delay_4_54','single_300ms_delay_4_55','single_300ms_delay_4_56',\n",
    "        'single_300ms_delay_4_81','single_300ms_delay_4_82','single_300ms_delay_4_83','single_300ms_delay_4_84','single_300ms_delay_4_85','single_300ms_delay_4_86',\n",
    "        'single_300ms_delay_4_91','single_300ms_delay_4_92','single_300ms_delay_4_93','single_300ms_delay_4_94','single_300ms_delay_4_95','single_300ms_delay_4_96']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tasks & Conditions pretest\n",
    "pretest_conds = ['short_tone_1','long_tone_6']\n",
    "subID = df_clean['sub_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select the main trials \n",
    "df_clean = df[(df['stimuli_presented'].isin(conds)) & (df['task'] == \"maintaskTrials\")].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select the pretest trials \n",
    "df_clean = df[(df['stimuli_presented'].isin(conds)) & (df['task'] == \"pretestTrials\")].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Long format for each condition\n",
    "# B/T: presenting order & response key\n",
    "# W/I: Onset time, comparison length, delay length\n",
    "df_clean['onset'] = df_clean['stimuli_presented'].apply(lambda x: x.split(\"_\")[-1][0])\n",
    "df_clean['delay'] = df_clean['stimuli_presented'].apply(lambda x: x.split(\"_\")[-2])\n",
    "df_clean['comparison'] = df_clean['stimuli_presented'].apply(lambda x: x.split(\"_\")[-1][1])\n",
    "df_clean['order'] = df_clean['group_id'].apply(lambda x: x.split(\"_\")[-1])\n",
    "df_clean['key'] = df_clean['group_id'].apply(lambda x: x.split(\"_\")[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme reaction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_longRT = df_clean[df_clean['response_rt'] > RT_threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze noise and overall accuracy/catch accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = noise.astype(int) # turn str to int to do correlaton\n",
    "acc = df_clean.groupby('sub_id')['response_correct'].sum()/\\\n",
    "df_clean.groupby('sub_id')['response_correct'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(noise,acc)[0,1]\n",
    "print(corr, '\\n')\n",
    "corr = np.corrcoef(noise,catch_acc)[0,1]\n",
    "print(corr, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data...\n",
    "plt.scatter(acc,noise,color='r')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data...\n",
    "plt.scatter(catch_acc,noise,color='r')\n",
    "plt.hist(catch_acc,noise)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze pretest trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pretest = df_clean[(df_clean['trial_template'].isin(pretest_trials))]\n",
    "#print(df_pretest.groupby(['participant_id','stimuli_presented']).mean()['Correct'])\n",
    "print(df_pretest.groupby(['stimuli_presented']).mean()['Correct'])\n",
    "print(df_pretest.groupby(['stimuli_presented']).mean()['Shorter'])\n",
    "print(np.mean(df_pretest['Shorter']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the onset and comparison length to the csv file for R analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant_number:\n",
      "67\n",
      "Trial number:\n",
      "1929\n",
      "Condition number:\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "## Number of subjects, trials & conditions for each subjects\n",
    "n_subj = len(df_clean['sub_id'].unique())\n",
    "n_trial = len(df_clean)//15\n",
    "n_conds = len(df_clean['stimuli_presented'].unique())\n",
    "print('Participant_number:', n_subj,'Trial number:', n_trial,'Condition number:', n_conds, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group_by\n",
    "overall_acc = df_clean.groupby(['sub_id']).mean()['Correct'].reset_index(drop = True)\n",
    "overall_pps = df_clean.groupby(['sub_id']).mean()['Shorter'].reset_index(drop = True)\n",
    "all_conds_acc = df_clean.groupby(['sub_id','onset','delay','comparison','order','key']).mean()['Correct'].reset_index(drop = True)\n",
    "all_conds_pps = df_clean.groupby(['sub_id','onset','delay','comparison','order','key']).mean()['Shorter'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save df to csv\n",
    "df_clean.to_csv(r'/Users/t.z.cheng/Google_Drive/Research/Delaydoesmatter/real_exp/exp4_20CR12/results_shortlongdelay_2021/v2_20CR12_clean_n67_cleaned.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze trials of the main task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = []\n",
    "Acc_cond = []\n",
    "Easiest = []\n",
    "Easiest_idx = [conds.index('single_300ms_delay_2_81'),conds.index('single_300ms_delay_2_86')]\n",
    "# Easiest_idx = [conds.index('single_300ms_delay_4_81'),conds.index('single_300ms_delay_4_86')]\n",
    "for sub in subID:\n",
    "    tmpdf = df_clean[df_clean['participant_id'] == sub]\n",
    "    for cond in conds:\n",
    "        tmpAcc = np.mean(tmpdf[tmpdf['stimuli_presented'] == cond]['response_correct'])\n",
    "        Acc_cond.append(tmpAcc)\n",
    "    Easiest.append((Acc_cond[Easiest_idx[0]] + Acc_cond[Easiest_idx[-1]])/len(Easiest_idx)) # average accuracy of 81 and 86 \n",
    "    Accuracy.append(Acc_cond)\n",
    "    Acc_cond = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Outliers based on the accuracy of the easiest trials \n",
    "Acc_easiest = pd.Series(Easiest, index=df_clean['participant_id'].unique())\n",
    "print(Acc_easiest.describe())\n",
    "t = Acc_easiest[Acc_easiest >= threshold]\n",
    "print(\"Subjects who have >=\",threshold, \"accuracy for the easiest trials:\",len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Accuracy = pd.DataFrame(data = Accuracy, index = subID, columns = conds)\n",
    "Acc_final_sample = df_Accuracy[Acc_easiest >= threshold]\n",
    "Acc_final_sample.head()\n",
    "print('Final sample size:', len(Acc_final_sample))\n",
    "# Acc_final_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Accuracy.index.name = 'participant_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = Acc_easiest < threshold\n",
    "outliers = outliers[outliers == True]\n",
    "df_clean_nooutlier = df_clean[~df_clean['participant_id'].isin(outliers.index)]\n",
    "len(df_clean_nooutlier)/216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Acc_final_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the dataset to csv\n",
    "# df_clean_nooutlier.to_csv(path_or_buf = '/Users/t.z.cheng/Google_Drive/Research/Delaydoesmatter/real_exp/exp4_20CR12/results/20CR12_clean_n53.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Early, ontime, late short delay\n",
    "early = [conds.index('single_300ms_delay_2_51'),conds.index('single_300ms_delay_2_52'),conds.index('single_300ms_delay_2_53'),conds.index('single_300ms_delay_2_54'),conds.index('single_300ms_delay_2_55'),conds.index('single_300ms_delay_2_56')]\n",
    "ontime = [conds.index('single_300ms_delay_2_81'),conds.index('single_300ms_delay_2_82'),conds.index('single_300ms_delay_2_83'),conds.index('single_300ms_delay_2_84'),conds.index('single_300ms_delay_2_85'),conds.index('single_300ms_delay_2_86')]\n",
    "late = [conds.index('single_300ms_delay_2_91'),conds.index('single_300ms_delay_2_92'),conds.index('single_300ms_delay_2_93'),conds.index('single_300ms_delay_2_94'),conds.index('single_300ms_delay_2_95'),conds.index('single_300ms_delay_2_96')]\n",
    "Acc_early = Acc_final_sample.iloc[:, early].mean(axis = 1)\n",
    "Acc_ontime = Acc_final_sample.iloc[:, ontime].mean(axis = 1)\n",
    "Acc_late = Acc_final_sample.iloc[:, late].mean(axis = 1)\n",
    "print(\"Accuracy\")\n",
    "print(\"Early:\", np.mean(Acc_early))\n",
    "print(\"Ontime:\", np.mean(Acc_ontime))\n",
    "print(\"Late:\",np.mean(Acc_late))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Early, ontime, late long delay\n",
    "early = [conds.index('single_300ms_delay_4_51'),conds.index('single_300ms_delay_4_52'),conds.index('single_300ms_delay_4_53'),conds.index('single_300ms_delay_4_54'),conds.index('single_300ms_delay_4_55'),conds.index('single_300ms_delay_4_56')]\n",
    "ontime = [conds.index('single_300ms_delay_4_81'),conds.index('single_300ms_delay_4_82'),conds.index('single_300ms_delay_4_83'),conds.index('single_300ms_delay_4_84'),conds.index('single_300ms_delay_4_85'),conds.index('single_300ms_delay_4_86')]\n",
    "late = [conds.index('single_300ms_delay_4_91'),conds.index('single_300ms_delay_4_92'),conds.index('single_300ms_delay_4_93'),conds.index('single_300ms_delay_4_94'),conds.index('single_300ms_delay_4_95'),conds.index('single_300ms_delay_4_96')]\n",
    "Acc_early = Acc_final_sample.iloc[:, early].mean(axis = 1)\n",
    "Acc_ontime = Acc_final_sample.iloc[:, ontime].mean(axis = 1)\n",
    "Acc_late = Acc_final_sample.iloc[:, late].mean(axis = 1)\n",
    "print(\"Accuracy\")\n",
    "print(\"Early:\", np.mean(Acc_early))\n",
    "print(\"Ontime:\", np.mean(Acc_ontime))\n",
    "print(\"Late:\",np.mean(Acc_late))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualization: bar plot\n",
    "ACC_plot = pd.DataFrame({'Conditions': conds, 'acc': np.mean(Acc_final_sample, axis = 0)})\n",
    "ax = ACC_plot.plot.bar(rot = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_short = []\n",
    "resp_short = [True if d == 'Shorter' else False for d in df_clean['response_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['resp_short'] = resp_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPS = []\n",
    "PPS_cond = []\n",
    "for sub in subID:\n",
    "    tmpdf = df_clean[df_clean['participant_id'] == sub]\n",
    "    for cond in conds:\n",
    "        tmpPPS = np.mean(tmpdf[tmpdf['stimuli_presented'] == cond]['resp_short'])\n",
    "        PPS_cond.append(tmpPPS)\n",
    "    PPS.append(PPS_cond)\n",
    "    PPS_cond = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PPS = pd.DataFrame(data = PPS, index = subID, columns = conds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPS_final_sample = df_PPS[Acc_easiest >= threshold]\n",
    "PPS_final_sample.head()\n",
    "PPS_final_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Early, ontime, late short\n",
    "early = [conds.index('single_300ms_delay_2_51'),conds.index('single_300ms_delay_2_52'),conds.index('single_300ms_delay_2_53'),conds.index('single_300ms_delay_2_54'),conds.index('single_300ms_delay_2_55'),conds.index('single_300ms_delay_2_56')]\n",
    "ontime = [conds.index('single_300ms_delay_2_81'),conds.index('single_300ms_delay_2_82'),conds.index('single_300ms_delay_2_83'),conds.index('single_300ms_delay_2_84'),conds.index('single_300ms_delay_2_85'),conds.index('single_300ms_delay_2_86')]\n",
    "late = [conds.index('single_300ms_delay_2_91'),conds.index('single_300ms_delay_2_92'),conds.index('single_300ms_delay_2_93'),conds.index('single_300ms_delay_2_94'),conds.index('single_300ms_delay_2_95'),conds.index('single_300ms_delay_2_96')]\n",
    "PPS_early = PPS_final_sample.iloc[:, early].mean(axis = 1)\n",
    "PPS_ontime = PPS_final_sample.iloc[:, ontime].mean(axis = 1)\n",
    "PPS_late = PPS_final_sample.iloc[:, late].mean(axis = 1)\n",
    "print(\"Proportion short\")\n",
    "print(\"Early:\", np.mean(PPS_early))\n",
    "print(\"Ontime:\", np.mean(PPS_ontime))\n",
    "print(\"Late:\",np.mean(PPS_late))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Early, ontime, late long\n",
    "early = [conds.index('single_300ms_delay_4_51'),conds.index('single_300ms_delay_4_52'),conds.index('single_300ms_delay_4_53'),conds.index('single_300ms_delay_4_54'),conds.index('single_300ms_delay_4_55'),conds.index('single_300ms_delay_4_56')]\n",
    "ontime = [conds.index('single_300ms_delay_4_81'),conds.index('single_300ms_delay_4_82'),conds.index('single_300ms_delay_4_83'),conds.index('single_300ms_delay_4_84'),conds.index('single_300ms_delay_4_85'),conds.index('single_300ms_delay_4_86')]\n",
    "late = [conds.index('single_300ms_delay_4_91'),conds.index('single_300ms_delay_4_92'),conds.index('single_300ms_delay_4_93'),conds.index('single_300ms_delay_4_94'),conds.index('single_300ms_delay_4_95'),conds.index('single_300ms_delay_4_96')]\n",
    "PPS_early = PPS_final_sample.iloc[:, early].mean(axis = 1)\n",
    "PPS_ontime = PPS_final_sample.iloc[:, ontime].mean(axis = 1)\n",
    "PPS_late = PPS_final_sample.iloc[:, late].mean(axis = 1)\n",
    "print(\"Proportion short\")\n",
    "print(\"Early:\", np.mean(PPS_early))\n",
    "print(\"Ontime:\", np.mean(PPS_ontime))\n",
    "print(\"Late:\",np.mean(PPS_late))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualization: bar plot\n",
    "PSS_plot = pd.DataFrame({'Conditions': conds, 'PSS': np.mean(PPS_final_sample, axis = 0)})\n",
    "ax = PSS_plot.plot.bar(rot = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistic tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.ttest_rel(PPS_early, PPS_late))\n",
    "print(stats.ttest_rel(PPS_early, PPS_ontime))\n",
    "print(stats.ttest_rel(PPS_late, PPS_ontime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
