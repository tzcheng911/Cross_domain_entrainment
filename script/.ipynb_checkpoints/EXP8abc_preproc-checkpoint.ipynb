{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## concat csv files\n",
    "# os.chdir(\"/Users/t.z.cheng/Google_Drive/Research/cross_domain_entrainment/exp8/results/\")\n",
    "# extension = 'csv'\n",
    "# all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "# combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "# combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the data\n",
    "# df = pd.read_csv(\"combined_csv.csv\")\n",
    "# df.groupby('stimuli_presented').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tasks & Conditions: Clean up task and subject ID (first five characters)\n",
    "df['task'] = df['trial_template'].apply(lambda x: x.split(\"_\")[1] if (x.split(\"_\")[0] == which_exp) else x.split(\"_\")[0])\n",
    "df['sub_id'] = df['participant_id'].apply(lambda x: x.split()[0][0:5])\n",
    "## for exp8abc\n",
    "df['exp'] = df['group_id'].apply(lambda x: x.split(\"_\")[0])\n",
    "df = df[(df['exp'] == which_exp)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the accuracy and PPS column to the dataset: transform True and Shorter to 1, False and longer to 0\n",
    "Correct = [] # only applied for the prescreen\n",
    "Shorter = []\n",
    "for i in np.arange(0,len(df)):\n",
    "    if df['response_correct'][i] == True:\n",
    "        Correct.append(1)\n",
    "    else: \n",
    "        Correct.append(0)\n",
    "    if ((df['response_value'][i] == \"Lap\") or (df['response_value'][i] == \"Shorter\")): \n",
    "        Shorter.append(1)\n",
    "    else: \n",
    "        Shorter.append(0)\n",
    "df['Correct'] = Correct\n",
    "df['Shorter'] = Shorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Total participated subjects\n",
    "len(df['sub_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'EXP8c_FJ'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4410\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4411\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4412\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w3/hvly9pws0r11d56ls2x71l1h0000gn/T/ipykernel_9771/1999507165.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'group_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'group_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sub_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EXP8c_FJ'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'group_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sub_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EXP8c_JF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4417\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4418\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4419\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4420\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4421\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4403\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4404\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4405\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4406\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'EXP8c_FJ'"
     ]
    }
   ],
   "source": [
    "df['exp'] = df['group_id'].apply(lambda x: x.split(\"_\")[0])\n",
    "print(len(df.groupby('group_id')['sub_id'].unique()['EXP8c_FJ']))\n",
    "print(len(df.groupby('group_id')['sub_id'].unique()['EXP8c_JF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_hear_speech = df[df[\"response_value\"] == \"Lab or Lap\"]['sub_id'].unique()\n",
    "subj_hear_tone = df[df[\"response_value\"] == \"Musical Tones\"]['sub_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sub_id'].isin(subj_hear_speech)].reset_index(drop = True)\n",
    "len(df['sub_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters\n",
    "- Accuracy threshold for the easiest trials of the main task \n",
    "- Extreme RT threshold\n",
    "- Catch trial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "threshold = .55\n",
    "catch_threshold = .7\n",
    "RT_threshold = 10000\n",
    "practice_threshold = 'pass'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning \n",
    "***Super important: df_clean is overwritten after each step of data cleaning***\n",
    "\n",
    "**Reject subjects**\n",
    "- Catch trial\n",
    "- Environmental noise & audio device (may not need to use them as criteria)\n",
    "- Fail the practice trial on the last 12 practice trial: pass people have done 24 trials, fail people have done 36 trials\n",
    "\n",
    "**Reject trials**\n",
    "- Task-relevant trials\n",
    "- Extreme RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_id</th>\n",
       "      <th>response_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>054a2</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06c85</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>292a2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40be2</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>759fe</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>76551</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c9f49</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d12f6</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f1726</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_id  response_correct\n",
       "0  054a2          0.423077\n",
       "1  06c85          0.461538\n",
       "2  292a2          0.500000\n",
       "3  40be2          0.615385\n",
       "4  759fe          0.692308\n",
       "5  76551          0.653846\n",
       "6  c9f49          0.576923\n",
       "7  d12f6          0.538462\n",
       "8  f1726          0.653846"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many subjects miss the catch trial \n",
    "catch_trials = ['Catch_trials'] ## for exp8abc\n",
    "\n",
    "df_catch = df[(df['trial_template'].isin(catch_trials))].reset_index(drop = True) # reset index from 1\n",
    "catch_acc = df_catch.groupby('sub_id')['response_correct'].sum()/df_catch.groupby('sub_id')['response_correct'].count()\n",
    "fail_catch = catch_acc[catch_acc < catch_threshold].reset_index()\n",
    "fail_catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove subjects who failed the catch trial based on the threshold\n",
    "df_clean = df[~df['sub_id'].isin(fail_catch['sub_id'])].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_id</th>\n",
       "      <th>response_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2eb6a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_id response_value\n",
       "0  2eb6a              4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many subjects had a bad environmental noise and device\n",
    "df_noise = df[(df['response_name'] == 'survey_noise')].reset_index(drop = True)\n",
    "noise = df_noise.groupby('sub_id')['response_value'].sum()\n",
    "too_noisy = noise[noise == '4'].reset_index()\n",
    "too_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove subjects who completed the task in noisy environment\n",
    "df_clean = df_clean[~df_clean['sub_id'].isin(too_noisy['sub_id'])].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# may remove subjects who completed the task using low-quality audio device\n",
    "df_device = df[(df['response_name'] == 'survey_headphone1')].reset_index()\n",
    "len(df_device[['sub_id','response_value']] == 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which_exp != 'EXP8a':\n",
    "    ## remove subjects who failed the practice \n",
    "    fail_prac = df[df['branch_failpass'] == 'fail']['sub_id'].unique()\n",
    "    len(fail_prac)\n",
    "    df_clean = df_clean[(~df_clean['sub_id'].isin(fail_prac))].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## After cleaning how many subjects left\n",
    "len(df_clean['sub_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task relevant trials\n",
    "#### Select the trials to analyze\n",
    "- Pretest trails (n = 60): single tone 1 or 8\n",
    "- Practice trials (n = 24 or 36): 6 context tones + 1 ontime single tone 1 or 8 with correct/incorrect feedback\n",
    "- Main task (n = 576): 6 context tones + 1 single tone (early, ontime, late; 1 to 8 steps) without feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the pretest trials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['logisticsQuestionnaire', 'Pretestexample', 'PretestTrials',\n",
       "       'example', 'practiceTrials', 'maintaskTrials', 'Catch',\n",
       "       'langBackground', 'musicBackground', 'basicDialogue', 'Tone'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['task'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['long_tone_8' 'short_tone_1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stimuli_presented\n",
       "long_tone_8     0.097561\n",
       "short_tone_1    0.921545\n",
       "Name: Shorter, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre = df_clean[(df_clean['task'] == \"PretestTrials\")].reset_index()\n",
    "df_pre.groupby(['sub_id','stimuli_presented'])['Correct'].mean()\n",
    "pre_acc = df_pre.groupby(['sub_id'])['Correct'].mean()\n",
    "conds = df_pre['stimuli_presented'].unique()\n",
    "print(conds) # check the conditions\n",
    "df_pre.groupby('stimuli_presented')['Shorter'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the practice trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['single_300ms_ontime_delay_2_tone_Lab_8'\n",
      " 'single_300ms_ontime_delay_2_tone_Lab_1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stimuli_presented\n",
       "single_300ms_ontime_delay_2_tone_Lab_1    0.916667\n",
       "single_300ms_ontime_delay_2_tone_Lab_8    0.093496\n",
       "Name: Shorter, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prac = df_clean[(df_clean['task'] == \"practiceTrials\")].reset_index()\n",
    "conds = df_prac['stimuli_presented'].unique()\n",
    "print(conds) # check the conditions\n",
    "df_prac.groupby('stimuli_presented')['Shorter'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_all = df_clean # create a new variable just in case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ??? under progress, need to write a code to save those *fail* who but pass on the last 12 trials??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pra = df_pra[-12:-1]\n",
    "# df_pra.groupby(['sub_id','stimuli_presented'])['Correct'].mean()\n",
    "# pra_acc = df_pra.groupby(['sub_id'])['Correct'].mean()\n",
    "# fail_pra = pra_acc[pra_acc != practice_threshold].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the main trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['single_300ms_ontime_delay_2_tone_Lab_7'\n",
      " 'single_300ms_early_delay_2_tone_Lab_6'\n",
      " 'single_300ms_early_delay_2_tone_Lab_5'\n",
      " 'single_300ms_late_delay_2_tone_Lab_2'\n",
      " 'single_300ms_early_delay_2_tone_Lab_8'\n",
      " 'single_300ms_ontime_delay_2_tone_Lab_1'\n",
      " 'single_300ms_ontime_delay_2_tone_Lab_4'\n",
      " 'single_300ms_late_delay_2_tone_Lab_1'\n",
      " 'single_300ms_late_delay_2_tone_Lab_3'\n",
      " 'single_300ms_late_delay_2_tone_Lab_8'\n",
      " 'single_300ms_ontime_delay_2_tone_Lab_8'\n",
      " 'single_300ms_late_delay_2_tone_Lab_7'\n",
      " 'single_300ms_early_delay_2_tone_Lab_1'\n",
      " 'single_300ms_late_delay_2_tone_Lab_4'\n",
      " 'single_300ms_ontime_delay_2_tone_Lab_6'\n",
      " 'single_300ms_ontime_delay_2_tone_Lab_2'\n",
      " 'single_300ms_late_delay_2_tone_Lab_5'\n",
      " 'single_300ms_early_delay_2_tone_Lab_3'\n",
      " 'single_300ms_late_delay_2_tone_Lab_6'\n",
      " 'single_300ms_early_delay_2_tone_Lab_7'\n",
      " 'single_300ms_early_delay_2_tone_Lab_4'\n",
      " 'single_300ms_ontime_delay_2_tone_Lab_5'\n",
      " 'single_300ms_early_delay_2_tone_Lab_2'\n",
      " 'single_300ms_ontime_delay_2_tone_Lab_3']\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_clean[(df_clean['task'] == \"maintaskTrials\")].reset_index(drop = True)\n",
    "conds = df_clean['stimuli_presented'].unique()\n",
    "print(conds) # check the conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new cols for onset and length\n",
    "onset = []\n",
    "length = []\n",
    "df_clean = df_clean.set_index(pd.Index(np.arange(0,len(df_clean)))) # change the index for the for loop\n",
    "\n",
    "for i in np.arange(0,len(df_clean)):\n",
    "    stimuli_presented = df_clean['stimuli_presented'][i].split('_')\n",
    "    onset.append(stimuli_presented[2])\n",
    "    length.append(stimuli_presented[-1])\n",
    "df_clean['Onset'] = onset\n",
    "df_clean['Length'] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant_number:\n",
      "82\n",
      "Trial number:\n",
      "288\n",
      "Condition number:\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "## Number of subjects, trials & conditions for each subjects\n",
    "n_subj = len(df_clean['participant_id'].unique())\n",
    "n_trial = len(df_clean)//n_subj # how many trials per subject\n",
    "n_conds = len(df_clean['stimuli_presented'].unique())\n",
    "print('Participant_number:', n_subj,'Trial number:', n_trial,'Condition number:', n_conds, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "#### Not for EXP8c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.groupby(['Onset'])['Correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_all = df_clean.groupby(['stimuli_presented','Onset'])['Correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## consider outliers based on the accuracy of the easiest trials \n",
    "outliers = Acc_easiest < threshold\n",
    "outliers = outliers[outliers == True]\n",
    "df_clean_nooutlier = df_clean[~df_clean['participant_id'].isin(outliers.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualization: bar plot\n",
    "ACC_plot = pd.DataFrame({'Conditions': conds, 'accuracy': accuracy_all})\n",
    "ax = ACC_plot.plot.bar(rot = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.groupby(['Onset'])['Shorter'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps = df_clean.groupby(['Onset'])['Shorter'].mean()\n",
    "print('Proportion short')\n",
    "print('Early',pps[0]) \n",
    "print('Ontime',pps[2])\n",
    "print('Late',pps[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps_all = df_clean.groupby(['stimuli_presented','Onset'])['Shorter'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualization: bar plot\n",
    "PPS_plot = pd.DataFrame({'Conditions': conds, 'PSS': pps_all})\n",
    "ax = PPS_plot.plot.bar(rot = 0)\n",
    "pps_all.plot(style='k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps_all[0:8].plot(style = 'o-') # early\n",
    "pps_all[8:16].plot(style ='ko-') # late\n",
    "ax = pps_all[16:24].plot(style ='ro-') # ontime\n",
    "ax.set_xticklabels([0,1,2,3,4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistic tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPS = df_clean.groupby(['sub_id','Onset'])['Shorter'].mean()\n",
    "PPS_early = PPS[::3]\n",
    "PPS_ontime = PPS[2::3]\n",
    "PPS_late = PPS[1::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.ttest_rel(PPS_early, PPS_late))\n",
    "print(stats.ttest_rel(PPS_early, PPS_ontime))\n",
    "print(stats.ttest_rel(PPS_late, PPS_ontime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the onset and comparison length to the csv file for R analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save df to csv\n",
    "df_clean.to_csv(r'/Users/t.z.cheng/Google_Drive/Research/Delaydoesmatter/real_exp/exp4_20CR12/4c/results/EXP4c_clean_n59.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
