count()
View(counting)
length(unique(countEXP$participant_id)) # how many subjects
countEXP = filter(EXP, trial_template == "DiscriminationTrials") # select the main trials after 8 examples
counting = countEXP %>%
group_by(stimuli_presented) %>%
count()
length(unique(countEXP$participant_id)) # how many subjects
countEXP = filter(EXP, trial_template == "PrescreenTrials_tones_rv") # "PrescreenTrials_tones_rv", "EXP9a_maintaskTrials"
counting = countEXP %>%
group_by(stimuli_presented) %>%
count()
length(unique(countEXP$participant_id)) # how many subjects
countEXP = filter(EXP, trial_template == "PrescreenTrials_tones") # "PrescreenTrials_tones_rv", "EXP9a_maintaskTrials"
counting = countEXP %>%
group_by(stimuli_presented) %>%
count()
length(unique(countEXP$participant_id)) # how many subjects
View(counting)
countEXP = filter(EXP, trial_template == "EXP9b_PretestTrials_rv") # Speech: "DiscriminationTrials_rv","EXP9a_maintaskTrials"; Tones:"EXP9b_PretestTrials_rv", PrescreenTrials_tones_rv"
counting = countEXP %>%
group_by(stimuli_presented) %>%
count()
length(unique(countEXP$participant_id)) # how many subjects
## Preprocessing
# Filter the discrimination task
DiscEXP = filter(EXP, trial_template == "DiscriminationTrials")
DiscEXP = DiscEXP %>%
mutate(len = str_sub(str_split(as.character(DiscEXP$stimuli_presented),"_",simplify = T)[,1],-1))
DiscEXP %>%
group_by(stimuli_presented) %>%
summarize(mean = mean(Shorter), SD = sd(Shorter))
## Preprocessing
# Filter the discrimination task
DiscEXP = filter(EXP, trial_template == "DiscriminationTrials_rv")
DiscEXP = DiscEXP %>%
mutate(len = str_sub(str_split(as.character(DiscEXP$stimuli_presented),"_",simplify = T)[,1],-1))
DiscEXP %>%
group_by(stimuli_presented) %>%
summarize(mean = mean(Shorter), SD = sd(Shorter))
## Preprocessing
# Filter the discrimination task
DiscEXP = filter(EXP, trial_template == "PrescreenTrials_tones")
DiscEXP = DiscEXP %>%
mutate(len = str_sub(str_split(as.character(DiscEXP$stimuli_presented),"_",simplify = T)[,1],-1))
DiscEXP %>%
group_by(stimuli_presented) %>%
summarize(mean = mean(Shorter), SD = sd(Shorter))
## Preprocessing
# Filter the discrimination task
DiscEXP = filter(EXP, trial_template == "EXP9b_PretestTrials")
DiscEXP = DiscEXP %>%
mutate(len = str_sub(str_split(as.character(DiscEXP$stimuli_presented),"_",simplify = T)[,1],-1))
DiscEXP %>%
group_by(stimuli_presented) %>%
summarize(mean = mean(Shorter), SD = sd(Shorter))
## Preprocessing
# Filter the discrimination task
DiscEXP = filter(EXP, trial_template == "EXP9b_PretestTrials_rv")
DiscEXP = DiscEXP %>%
mutate(len = str_sub(str_split(as.character(DiscEXP$stimuli_presented),"_",simplify = T)[,1],-1))
DiscEXP %>%
group_by(stimuli_presented) %>%
summarize(mean = mean(Shorter), SD = sd(Shorter))
# Filter the main task
# Coding response to 0: out of time, and 1: in time
# mutate the conditions: stimuli (ad/at, lab/lap, tone/tone1), delay (metronome is 0,30,60,90,120 ms behind the sound), len (short 1, long 8)
mainEXP = filter(EXP, trial_template == "EXP9b_maintaskTrials") # select the main trials after 8 examples
length(unique(mainEXP$participant_id)) # how many subjects
mainEXP = mainEXP %>%
mutate(onset = str_split(as.character(mainEXP$stimuli_presented),"_",simplify = T)[,1])
mainEXP = mainEXP %>%
mutate(len = str_sub(str_split(as.character(mainEXP$stimuli_presented),"_",simplify = T)[,2],-1))
mainEXP$onset = factor(mainEXP$onset, levels = c("early","ontime","late"))
mainEXP$len = factor(mainEXP$len, levels = c("1","2","3","4","5","6","7","8"))
## Check the stimuli presentation: divide by # of subjects should be the same
# Speech: "DiscriminationTrials_rv","EXP9a_maintaskTrials"; Tones:"EXP9b_PretestTrials_rv", PrescreenTrials_tones_rv"
countEXP = filter(EXP, trial_template == "EXP9b_PretestTrials_rv")
counting = countEXP %>%
group_by(stimuli_presented) %>%
count()
length(unique(countEXP$participant_id)) # how many subjects
## Analysis
mainEXPmeans=mainEXP %>%
group_by(onset,len) %>%
summarize(mean = mean(Shorter), SD = sd(Shorter))
mainEXP %>%
group_by(onset) %>%
summarize(mean = mean(Shorter), SD = sd(Shorter))
# Filter the main task
# Coding response to 0: out of time, and 1: in time
# mutate the conditions: stimuli (ad/at, lab/lap, tone/tone1), delay (metronome is 0,30,60,90,120 ms behind the sound), len (short 1, long 8)
mainEXP = filter(EXP, trial_template == "EXP9b_maintaskTrials_rv") # select the main trials after 8 examples
length(unique(mainEXP$participant_id)) # how many subjects
mainEXP = mainEXP %>%
mutate(onset = str_split(as.character(mainEXP$stimuli_presented),"_",simplify = T)[,1])
mainEXP = mainEXP %>%
mutate(len = str_sub(str_split(as.character(mainEXP$stimuli_presented),"_",simplify = T)[,2],-1))
mainEXP$onset = factor(mainEXP$onset, levels = c("early","ontime","late"))
mainEXP$len = factor(mainEXP$len, levels = c("1","2","3","4","5","6","7","8"))
mainEXP %>%
group_by(onset) %>%
summarize(mean = mean(Shorter), SD = sd(Shorter))
library(lme4)
library(lmerTest)
library(tidyverse)
library(broom)
library(ggplot2)
library(ggpubr)
library('fastDummies')
library(effsize)
library(lsr)
EXPspeech = read.csv("/Users/t.z.cheng/Documents/GitHub/Cross_domain_entrainment/exp9ab/results/EXP9a_clean_n79.csv")
EXPtone = read.csv("/Users/t.z.cheng/Documents/GitHub/Cross_domain_entrainment/exp9ab/results/EXP9b_clean_n76.csv")
## EXP8: 3 conditions
alldata=rbind(select(EXPtone,participant_id,sub_id,exp,Onset,Length,Shorter,Correct),select(EXPspeech,participant_id,sub_id,exp,Onset,Length,Shorter,Correct),
select(EXPtoneasspeech,participant_id,sub_id,exp,Onset,Length,Shorter,Correct))
## EXP9: 2 conditions
alldata=rbind(select(EXPtone,participant_id,sub_id,exp,Onset,Length,Shorter,Correct),select(EXPspeech,participant_id,sub_id,exp,Onset,Length,Shorter,Correct))
## Rescale and mutate new factors
alldata = alldata %>%
mutate(rLength = scale(Length, center = TRUE, scale = TRUE)) # scale the steps ## 4c: scale Length; 6: scale comparison
alldata = alldata %>%
mutate(fOnset = as.factor(Onset))
alldata = alldata %>%
mutate(Explabel = as.factor(exp))
## Onset coding and reference
alldata$fOnsetR = relevel(alldata$fOnset, ref="ontime") # make ontime condition the reference
alldata$fOnsetE = relevel(alldata$fOnset, ref="early") # make early condition the reference
alldata$OnsetNum=ifelse(alldata$fOnsetR=="early",-1,ifelse(alldata$fOnsetR=="ontime",0,1))
alldata$OnsetHelm1=ifelse(alldata$fOnsetR=="early",2/3,-1/3)
alldata$OnsetHelm2=ifelse(alldata$fOnsetR=="early",0,ifelse(alldata$fOnsetR=="ontime",1/2,-1/2))
## sort the data to be subjects x onset for each experiment
aovdata=alldata %>% #filter(comparison>=6) %>% ### if you limit speech to continua 1-5, no diffs. strong for 6-8
group_by(fOnsetR,Explabel,fOnset,rLength,sub_id) %>% summarise(Shorter=mean(Shorter)) # change rLength to Length for visualization
## sort the data to be subjects x onset for each experiment
aovdata=alldata %>% #filter(comparison>=6) %>% ### if you limit speech to continua 1-5, no diffs. strong for 6-8
group_by(fOnsetR,Explabel,fOnset,Length,sub_id) %>% summarise(Shorter=mean(Shorter)) # change rLength to Length for visualization
# run logistic fit on each subject and condition
aovmeans=aovdata %>%
group_by(sub_id,fOnsetR,Explabel) %>%
do(glmfit = glm(Shorter ~ rLength,data =.,family=binomial()))
# get the coefficients
aovmeans = aovmeans %>%
mutate(intercept = coef(glmfit)[1], slope = coef(glmfit)[2], fifty = -coef(glmfit)[1]/coef(glmfit)[2], deviance = glmfit$aic)
# mutate columes of pps
pps = aovdata %>% group_by(sub_id,fOnsetR,Explabel) %>% summarise(ShorterM=mean(Shorter),ShorterSD=sd(Shorter),Nsubs=n_distinct(sub_id),SE=ShorterSD/sqrt(Nsubs))
aovmeans = cbind(pps$ShorterM,aovmeans)
colnames(aovmeans)[1] = 'Shorter'
## EXP9 flag outliers based on slope
# who have reverse slopes, flat lines
# '8db1d','074c2' press the same button across all experiment
aovmeans$outliers_slope = ifelse(aovmeans$slope>= 0 | aovmeans$sub_id == '8db1d' | aovmeans$sub_id == '074c2',1,0)
outliers_slope_subj = filter(aovmeans,outliers_slope==1)
aovmeans_clean1 = filter(aovmeans, !(sub_id %in% unique(outliers_slope_subj$sub_id)))
# IQR criteria
q1 = quantile(aovmeans_clean1$fifty,.25)
q3 = quantile(aovmeans_clean1$fifty,.75)
iqr = IQR(aovmeans_clean1$fifty)
aovmeans_clean1$outliers_50 = ifelse(aovmeans_clean1$fifty < (q1 - 1.5*iqr) | aovmeans_clean1$fifty > (q3 + 1.5*iqr),1,0)
outliers_subj_50 = filter(aovmeans_clean1,outliers_50==1)
aovmeans_clean2 = filter(aovmeans_clean1, !(sub_id %in% unique(outliers_subj_50$sub_id)))
aovmeans_clean1 = filter(aovmeans, !(sub_id %in% unique(outliers_slope_subj$sub_id)))
# run logistic fit on each subject and condition
aovmeans=aovdata %>%
group_by(sub_id,fOnsetR,Explabel) %>%
do(glmfit = glm(Shorter ~ Length,data =.,family=binomial()))
# get the coefficients
aovmeans = aovmeans %>%
mutate(intercept = coef(glmfit)[1], slope = coef(glmfit)[2], fifty = -coef(glmfit)[1]/coef(glmfit)[2], deviance = glmfit$aic)
# mutate columes of pps
pps = aovdata %>% group_by(sub_id,fOnsetR,Explabel) %>% summarise(ShorterM=mean(Shorter),ShorterSD=sd(Shorter),Nsubs=n_distinct(sub_id),SE=ShorterSD/sqrt(Nsubs))
aovmeans = cbind(pps$ShorterM,aovmeans)
colnames(aovmeans)[1] = 'Shorter'
## EXP9 flag outliers based on slope
# who have reverse slopes, flat lines
# '8db1d','074c2' press the same button across all experiment
aovmeans$outliers_slope = ifelse(aovmeans$slope>= 0 | aovmeans$sub_id == '8db1d' | aovmeans$sub_id == '074c2',1,0)
outliers_slope_subj = filter(aovmeans,outliers_slope==1)
aovmeans_clean1 = filter(aovmeans, !(sub_id %in% unique(outliers_slope_subj$sub_id)))
# IQR criteria
q1 = quantile(aovmeans_clean1$fifty,.25)
q3 = quantile(aovmeans_clean1$fifty,.75)
iqr = IQR(aovmeans_clean1$fifty)
aovmeans_clean1$outliers_50 = ifelse(aovmeans_clean1$fifty < (q1 - 1.5*iqr) | aovmeans_clean1$fifty > (q3 + 1.5*iqr),1,0)
outliers_subj_50 = filter(aovmeans_clean1,outliers_50==1)
aovmeans_clean2 = filter(aovmeans_clean1, !(sub_id %in% unique(outliers_subj_50$sub_id)))
# Descriptive stats
aovmeans_clean2 %>%
group_by(Explabel,fOnsetR) %>%
summarize(mean(fifty),mean(intercept),mean(Shorter))
# plot overall results
aovdata_clean = filter(aovdata, sub_id %in% unique(aovmeans_clean2$sub_id))
aovdata_outlier_slope = filter(aovdata, sub_id %in% unique(outliers_slope_subj$sub_id))
aovdata_outlier_50 = filter(aovdata, sub_id %in% unique(outliers_subj_50$sub_id))
aovdata_clean$fOnsetR = factor(aovdata_clean$fOnsetR, levels = c("early","ontime","late"))
aovdata_outlier_slope$fOnsetR = factor(aovdata_outlier_slope$fOnsetR, levels = c("early","ontime","late"))
aovdata_outlier_50$fOnsetR = factor(aovdata_outlier_50$fOnsetR, levels = c("early","ontime","late"))
##EXP9
aovdata_clean_plot = aovdata_clean %>% group_by(rLength,fOnsetR,Explabel) %>% summarise(mShorter=mean(Shorter),SD=sd(Shorter),Nsubs=n_distinct(sub_id))
aovdata_clean_plot$fOnsetR = factor(aovdata_clean_plot$fOnsetR, levels = c("early","ontime","late"))
aovdata_clean$Explabel = factor(aovdata_clean$Explabel, levels = c("EXP9a","EXP9b"))
aovdata_outlier_slope$Explabel = factor(aovdata_outlier_slope$Explabel, levels = c("EXP9a","EXP9b"))
aovdata_outlier_50$Explabel = factor(aovdata_outlier_50$Explabel, levels = c("EXP9a","EXP9b"))
##EXP9
aovdata_clean_plot = aovdata_clean %>% group_by(Length,fOnsetR,Explabel) %>% summarise(mShorter=mean(Shorter),SD=sd(Shorter),Nsubs=n_distinct(sub_id))
aovdata_clean_plot$fOnsetR = factor(aovdata_clean_plot$fOnsetR, levels = c("early","ontime","late"))
aovdata_clean_plot$Explabel = factor(aovdata_clean_plot$Explabel, levels = c("EXP9a","EXP9b"))
ggplot(aovdata_clean_plot,aes(x=Length,y=mShorter,color=fOnsetR,linetype=Explabel,group=interaction(fOnsetR,Explabel)))+
geom_point()+
scale_x_continuous(breaks = seq(1, 8, by = 1))+
geom_line()+
geom_errorbar(aes(ymin=mShorter-SD/sqrt(Nsubs),ymax=mShorter+SD/sqrt(Nsubs)),width=0)+
facet_grid(Explabel~.)
## EXP9 relabel
aovmeans_clean2$Explabel = ifelse(aovmeans_clean2$Explabel == "EXP9a","Speech","Tones")
aovmeans_clean2$Explabel = factor(aovmeans_clean2$Explabel, levels = c("Speech","Tones"))
aovmeans_clean2$fOnsetR = factor(aovmeans_clean2$fOnsetR, levels = c("early","ontime","late"))
ggplot(aovmeans_clean2, aes(x = Explabel, y = fifty, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = fifty, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0,8) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = Shorter, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0,1)
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = Shorter, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0.2,0.8)
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = fifty, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0.1,0.75) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = Shorter, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0.2,0.85)
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = Shorter, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = Shorter, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0,0.8) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = Shorter, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0.1,0.8) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = fifty, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0,8) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = Shorter, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0.1,0.8) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = fifty, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(1,7.5) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
## sc updated 03/20/2023
## Load the data
EXPtone = read.csv("/Users/t.z.cheng/Google_Drive/Research/cross_domain_entrainment/exp8/results/old/EXP8b_clean_n84.csv")
EXPspeech = read.csv("/Users/t.z.cheng/Google_Drive/Research/cross_domain_entrainment/exp8/results/old/EXP8a_clean_n80.csv")
EXPtoneasspeech = read.csv("/Users/t.z.cheng/Google_Drive/Research/cross_domain_entrainment/exp8/results/old/EXP8c_clean_n88.csv")
## EXP8: 3 conditions
alldata=rbind(select(EXPtone,participant_id,sub_id,exp,Onset,Length,Shorter,Correct),select(EXPspeech,participant_id,sub_id,exp,Onset,Length,Shorter,Correct),
select(EXPtoneasspeech,participant_id,sub_id,exp,Onset,Length,Shorter,Correct))
## Rescale and mutate new factors
alldata = alldata %>%
mutate(rLength = scale(Length, center = TRUE, scale = TRUE)) # scale the steps ## 4c: scale Length; 6: scale comparison
alldata = alldata %>%
mutate(fOnset = as.factor(Onset))
alldata = alldata %>%
mutate(Explabel = as.factor(exp))
## Onset coding and reference
alldata$fOnsetR = relevel(alldata$fOnset, ref="ontime") # make ontime condition the reference
alldata$fOnsetE = relevel(alldata$fOnset, ref="early") # make early condition the reference
alldata$OnsetNum=ifelse(alldata$fOnsetR=="early",-1,ifelse(alldata$fOnsetR=="ontime",0,1))
alldata$OnsetHelm1=ifelse(alldata$fOnsetR=="early",2/3,-1/3)
alldata$OnsetHelm2=ifelse(alldata$fOnsetR=="early",0,ifelse(alldata$fOnsetR=="ontime",1/2,-1/2))
## sort the data to be subjects x onset for each experiment
aovdata=alldata %>% #filter(comparison>=6) %>% ### if you limit speech to continua 1-5, no diffs. strong for 6-8
group_by(fOnsetR,Explabel,OnsetNum,rLength,sub_id) %>% summarise(Shorter=mean(Shorter)) # change rLength to Length for visualization
# run logistic fit on each subject and condition
aovmeans=aovdata %>%
group_by(sub_id,fOnsetR,Explabel) %>%
do(glmfit = glm(Shorter ~ Length,data =.,family=binomial()))
## sort the data to be subjects x onset for each experiment
aovdata=alldata %>% #filter(comparison>=6) %>% ### if you limit speech to continua 1-5, no diffs. strong for 6-8
group_by(fOnsetR,Explabel,OnsetNum,Length,sub_id) %>% summarise(Shorter=mean(Shorter)) # change rLength to Length for visualization
# run logistic fit on each subject and condition
aovmeans=aovdata %>%
group_by(sub_id,fOnsetR,Explabel) %>%
do(glmfit = glm(Shorter ~ Length,data =.,family=binomial()))
# get the coefficients
aovmeans = aovmeans %>%
mutate(intercept = coef(glmfit)[1], slope = coef(glmfit)[2], fifty = -coef(glmfit)[1]/coef(glmfit)[2], deviance = glmfit$aic)
# mutate columes of pps
pps = aovdata %>% group_by(sub_id,fOnsetR,Explabel) %>% summarise(ShorterM=mean(Shorter),ShorterSD=sd(Shorter),Nsubs=n_distinct(sub_id),SE=ShorterSD/sqrt(Nsubs))
aovmeans = cbind(pps$ShorterM,aovmeans)
colnames(aovmeans)[1] = 'Shorter'
## EXP9 flag outliers based on slope
# who have reverse slopes, flat lines
# '8db1d','074c2' press the same button across all experiment
aovmeans$outliers_slope = ifelse(aovmeans$slope>= 0 | aovmeans$sub_id == '8db1d' | aovmeans$sub_id == '074c2',1,0)
outliers_slope_subj = filter(aovmeans,outliers_slope==1)
aovmeans_clean1 = filter(aovmeans, !(sub_id %in% unique(outliers_slope_subj$sub_id)))
## EXP8 flag outliers based on slope
# who have reverse slopes, flat lines
# 'af90a' press the same button across all experiment
aovmeans$outliers_slope = ifelse(aovmeans$slope>= 0 | aovmeans$sub_id == 'af90a',1,0)
outliers_slope_subj = filter(aovmeans,outliers_slope==1)
aovmeans_clean1 = filter(aovmeans, !(sub_id %in% unique(outliers_slope_subj$sub_id)))
# IQR criteria
q1 = quantile(aovmeans_clean1$fifty,.25)
q3 = quantile(aovmeans_clean1$fifty,.75)
iqr = IQR(aovmeans_clean1$fifty)
aovmeans_clean1$outliers_50 = ifelse(aovmeans_clean1$fifty < (q1 - 1.5*iqr) | aovmeans_clean1$fifty > (q3 + 1.5*iqr),1,0)
outliers_subj_50 = filter(aovmeans_clean1,outliers_50==1)
aovmeans_clean2 = filter(aovmeans_clean1, !(sub_id %in% unique(outliers_subj_50$sub_id)))
# Descriptive stats
aovmeans_clean2 %>%
group_by(Explabel,fOnsetR) %>%
summarize(mean(fifty),mean(intercept),mean(Shorter))
# plot overall results
aovdata_clean = filter(aovdata, sub_id %in% unique(aovmeans_clean2$sub_id))
aovdata_outlier_slope = filter(aovdata, sub_id %in% unique(outliers_slope_subj$sub_id))
aovdata_outlier_50 = filter(aovdata, sub_id %in% unique(outliers_subj_50$sub_id))
aovdata_clean$fOnsetR = factor(aovdata_clean$fOnsetR, levels = c("early","ontime","late"))
aovdata_outlier_slope$fOnsetR = factor(aovdata_outlier_slope$fOnsetR, levels = c("early","ontime","late"))
aovdata_outlier_50$fOnsetR = factor(aovdata_outlier_50$fOnsetR, levels = c("early","ontime","late"))
## EXP8
aovdata_clean$Explabel = factor(aovdata_clean$Explabel, levels = c("EXP8a","EXP8b","EXP8c"))
aovdata_clean_plot = aovdata_clean %>% group_by(rLength,fOnsetR,Explabel) %>% summarise(mShorter=mean(Shorter),SD=sd(Shorter),Nsubs=n_distinct(sub_id))
aovdata_clean_plot = aovdata_clean %>% group_by(Length,fOnsetR,Explabel) %>% summarise(mShorter=mean(Shorter),SD=sd(Shorter),Nsubs=n_distinct(sub_id))
aovdata_clean_plot$fOnsetR = factor(aovdata_clean_plot$fOnsetR, levels = c("early","ontime","late"))
ggplot(aovdata_clean_plot,aes(x=Length,y=mShorter,color=fOnsetR,linetype=Explabel,group=interaction(fOnsetR,Explabel)))+
geom_point()+
scale_x_continuous(breaks = seq(1, 8, by = 1))+
geom_line()+
geom_errorbar(aes(ymin=mShorter-SD/sqrt(Nsubs),ymax=mShorter+SD/sqrt(Nsubs)),width=0)+
facet_grid(Explabel~.)
## EXP8 relabel
aovmeans_clean2$Explabel = ifelse(aovmeans_clean2$Explabel == "EXP8a","Speech",ifelse(aovmeans_clean2$Explabel == "EXP8b","Tones","ToneasSpeech"))
aovmeans_clean2$Explabel = factor(aovmeans_clean2$Explabel, levels = c("Speech","Tones","ToneasSpeech"))
## EXP9 relabel
aovmeans_clean2$Explabel = ifelse(aovmeans_clean2$Explabel == "EXP9a","Speech","Tones")
aovmeans_clean2$Explabel = factor(aovmeans_clean2$Explabel, levels = c("Speech","Tones"))
aovmeans_clean2$fOnsetR = factor(aovmeans_clean2$fOnsetR, levels = c("early","ontime","late"))
ggplot(aovmeans_clean2, aes(x = Explabel, y = fifty, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = fifty, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0.1,0.8) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = fifty, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(1,7.5) +
ggplot(aovmeans_clean2, aes(x = Explabel, y = Shorter, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0.1,0.8) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = Shorter, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0.1,0.8) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = Shorter, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0,0.8) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = fifty, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(1,7.5) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = fifty, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0,7.5) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
## Load the data
EXPspeech = read.csv("/Users/t.z.cheng/Documents/GitHub/Cross_domain_entrainment/exp9ab/results/EXP9a_clean_n79.csv")
EXPtone = read.csv("/Users/t.z.cheng/Documents/GitHub/Cross_domain_entrainment/exp9ab/results/EXP9b_clean_n76.csv")
## Load the data
EXPspeech = read.csv("/Users/t.z.cheng/Documents/GitHub/Cross_domain_entrainment/exp9ab/results/EXP9a_clean_n79.csv")
EXPtone = read.csv("/Users/t.z.cheng/Documents/GitHub/Cross_domain_entrainment/exp9ab/results/EXP9b_clean_n76.csv")
## EXP9: 2 conditions
alldata=rbind(select(EXPtone,participant_id,sub_id,exp,Onset,Length,Shorter,Correct),select(EXPspeech,participant_id,sub_id,exp,Onset,Length,Shorter,Correct))
## Rescale and mutate new factors
alldata = alldata %>%
mutate(rLength = scale(Length, center = TRUE, scale = TRUE)) # scale the steps ## 4c: scale Length; 6: scale comparison
alldata = alldata %>%
mutate(fOnset = as.factor(Onset))
alldata = alldata %>%
mutate(Explabel = as.factor(exp))
## Onset coding and reference
alldata$fOnsetR = relevel(alldata$fOnset, ref="ontime") # make ontime condition the reference
alldata$fOnsetE = relevel(alldata$fOnset, ref="early") # make early condition the reference
alldata$OnsetNum=ifelse(alldata$fOnsetR=="early",-1,ifelse(alldata$fOnsetR=="ontime",0,1))
alldata$OnsetHelm1=ifelse(alldata$fOnsetR=="early",2/3,-1/3)
alldata$OnsetHelm2=ifelse(alldata$fOnsetR=="early",0,ifelse(alldata$fOnsetR=="ontime",1/2,-1/2))
## sort the data to be subjects x onset for each experiment
aovdata=alldata %>% #filter(comparison>=6) %>% ### if you limit speech to continua 1-5, no diffs. strong for 6-8
group_by(fOnsetR,Explabel,fOnset,rLength,sub_id) %>% summarise(Shorter=mean(Shorter)) # change rLength to Length for visualization
# run logistic fit on each subject and condition
aovmeans=aovdata %>%
group_by(sub_id,fOnsetR,Explabel) %>%
do(glmfit = glm(Shorter ~ rLength,data =.,family=binomial()))
## sort the data to be subjects x onset for each experiment
aovdata=alldata %>% #filter(comparison>=6) %>% ### if you limit speech to continua 1-5, no diffs. strong for 6-8
group_by(fOnsetR,Explabel,fOnset,Length,sub_id) %>% summarise(Shorter=mean(Shorter)) # change rLength to Length for visualization
# run logistic fit on each subject and condition
aovmeans=aovdata %>%
group_by(sub_id,fOnsetR,Explabel) %>%
do(glmfit = glm(Shorter ~ Length,data =.,family=binomial()))
# get the coefficients
aovmeans = aovmeans %>%
mutate(intercept = coef(glmfit)[1], slope = coef(glmfit)[2], fifty = -coef(glmfit)[1]/coef(glmfit)[2], deviance = glmfit$aic)
# mutate columes of pps
pps = aovdata %>% group_by(sub_id,fOnsetR,Explabel) %>% summarise(ShorterM=mean(Shorter),ShorterSD=sd(Shorter),Nsubs=n_distinct(sub_id),SE=ShorterSD/sqrt(Nsubs))
aovmeans = cbind(pps$ShorterM,aovmeans)
colnames(aovmeans)[1] = 'Shorter'
## EXP9 flag outliers based on slope
# who have reverse slopes, flat lines
# '8db1d','074c2' press the same button across all experiment
aovmeans$outliers_slope = ifelse(aovmeans$slope>= 0 | aovmeans$sub_id == '8db1d' | aovmeans$sub_id == '074c2',1,0)
outliers_slope_subj = filter(aovmeans,outliers_slope==1)
aovmeans_clean1 = filter(aovmeans, !(sub_id %in% unique(outliers_slope_subj$sub_id)))
# IQR criteria
q1 = quantile(aovmeans_clean1$fifty,.25)
q3 = quantile(aovmeans_clean1$fifty,.75)
iqr = IQR(aovmeans_clean1$fifty)
aovmeans_clean1$outliers_50 = ifelse(aovmeans_clean1$fifty < (q1 - 1.5*iqr) | aovmeans_clean1$fifty > (q3 + 1.5*iqr),1,0)
outliers_subj_50 = filter(aovmeans_clean1,outliers_50==1)
aovmeans_clean2 = filter(aovmeans_clean1, !(sub_id %in% unique(outliers_subj_50$sub_id)))
# Descriptive stats
aovmeans_clean2 %>%
group_by(Explabel,fOnsetR) %>%
summarize(mean(fifty),mean(intercept),mean(Shorter))
# plot overall results
aovdata_clean = filter(aovdata, sub_id %in% unique(aovmeans_clean2$sub_id))
aovdata_outlier_slope = filter(aovdata, sub_id %in% unique(outliers_slope_subj$sub_id))
aovdata_outlier_50 = filter(aovdata, sub_id %in% unique(outliers_subj_50$sub_id))
aovdata_clean$fOnsetR = factor(aovdata_clean$fOnsetR, levels = c("early","ontime","late"))
aovdata_outlier_slope$fOnsetR = factor(aovdata_outlier_slope$fOnsetR, levels = c("early","ontime","late"))
aovdata_outlier_50$fOnsetR = factor(aovdata_outlier_50$fOnsetR, levels = c("early","ontime","late"))
##EXP9
aovdata_clean_plot = aovdata_clean %>% group_by(rLength,fOnsetR,Explabel) %>% summarise(mShorter=mean(Shorter),SD=sd(Shorter),Nsubs=n_distinct(sub_id))
aovdata_clean_plot$fOnsetR = factor(aovdata_clean_plot$fOnsetR, levels = c("early","ontime","late"))
aovdata_clean$Explabel = factor(aovdata_clean$Explabel, levels = c("EXP9a","EXP9b"))
aovdata_outlier_slope$Explabel = factor(aovdata_outlier_slope$Explabel, levels = c("EXP9a","EXP9b"))
aovdata_outlier_50$Explabel = factor(aovdata_outlier_50$Explabel, levels = c("EXP9a","EXP9b"))
##EXP9
aovdata_clean_plot = aovdata_clean %>% group_by(Length,fOnsetR,Explabel) %>% summarise(mShorter=mean(Shorter),SD=sd(Shorter),Nsubs=n_distinct(sub_id))
aovdata_clean_plot$fOnsetR = factor(aovdata_clean_plot$fOnsetR, levels = c("early","ontime","late"))
aovdata_clean$Explabel = factor(aovdata_clean$Explabel, levels = c("EXP9a","EXP9b"))
aovdata_clean_plot$Explabel = factor(aovdata_clean_plot$Explabel, levels = c("EXP9a","EXP9b"))
## EXP9 relabel
aovmeans_clean2$Explabel = ifelse(aovmeans_clean2$Explabel == "EXP9a","Speech","Tones")
aovmeans_clean2$Explabel = factor(aovmeans_clean2$Explabel, levels = c("Speech","Tones"))
aovmeans_clean2$fOnsetR = factor(aovmeans_clean2$fOnsetR, levels = c("early","ontime","late"))
ggplot(aovmeans_clean2, aes(x = Explabel, y = Shorter, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0,0.8) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
ggplot(aovmeans_clean2, aes(x = Explabel, y = fifty, fill = fOnsetR)) +
geom_boxplot(outlier.size = 0) +
ylim(0,7.5) +
geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
labs(x = "Onset")
library(lme4)
library(lmerTest)
library(tidyverse)
library(broom)
library(ggplot2)
library(ggpubr)
library('fastDummies')
library(effsize)
library(lsr)
EXPspeech = read.csv("/Users/t.z.cheng/Documents/GitHub/Cross_domain_entrainment/exp9ab/results/EXP9a_clean_n79.csv")
EXPtone = read.csv("/Users/t.z.cheng/Documents/GitHub/Cross_domain_entrainment/exp9ab/results/EXP9b_clean_n76.csv")
## sc updated 03/20/2023
## Load the data
EXPtone = read.csv("/Users/t.z.cheng/Google_Drive/Research/cross_domain_entrainment/exp8/results/old/EXP8b_clean_n84.csv")
EXPspeech = read.csv("/Users/t.z.cheng/Google_Drive/Research/cross_domain_entrainment/exp8/results/old/EXP8a_clean_n80.csv")
EXPtoneasspeech = read.csv("/Users/t.z.cheng/Google_Drive/Research/cross_domain_entrainment/exp8/results/old/EXP8c_clean_n88.csv")
