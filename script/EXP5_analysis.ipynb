{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics # confusion matrix, MSE etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/Users/t.z.cheng/Google_Drive/Research/Delaydoesmatter/real_exp/exp5_21CR01/results/session-5ffcf-6007b-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the data\n",
    "df = pd.read_csv(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tasks & Conditions: filled\n",
    "ftasks = ['f_maintaskTrials_2_l','f_maintaskTrials_2_s']\n",
    "fconds = ['f300ms_delay_2_51','f300ms_delay_2_52','f300ms_delay_2_53','f300ms_delay_2_54','f300ms_delay_2_55','f300ms_delay_2_56',\n",
    "        'f300ms_delay_2_81','f300ms_delay_2_82','f300ms_delay_2_83','f300ms_delay_2_84','f300ms_delay_2_85','f300ms_delay_2_86',\n",
    "        'f300ms_delay_2_91','f300ms_delay_2_92','f300ms_delay_2_93','f300ms_delay_2_94','f300ms_delay_2_95','f300ms_delay_2_96']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tasks & Conditions: empty\n",
    "etasks = ['e_maintaskTrials_2_l','e_maintaskTrials_2_s']\n",
    "econds = ['e300ms_delay_2_51','e300ms_delay_2_52','e300ms_delay_2_53','e300ms_delay_2_54','e300ms_delay_2_55','e300ms_delay_2_56',\n",
    "        'e300ms_delay_2_81','e300ms_delay_2_82','e300ms_delay_2_83','e300ms_delay_2_84','e300ms_delay_2_85','e300ms_delay_2_86',\n",
    "        'e300ms_delay_2_91','e300ms_delay_2_92','e300ms_delay_2_93','e300ms_delay_2_94','e300ms_delay_2_95','e300ms_delay_2_96']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "threshold = 0\n",
    "conds = econds\n",
    "tasks = etasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "subID = df['participant_id'].unique()\n",
    "df_clean = df[(df['stimuli_presented'].isin(conds)) & (df['trial_template'].isin(tasks))]\n",
    "env_noise = df[(df['response_name'] == 'survey_noise')]['response_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant_number:\n",
      "29\n",
      "Trial number:\n",
      "432\n",
      "Condition number:\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "## Number of subjects, trials & conditions for each subjects for each trial type (empty vs filled)\n",
    "n_subj = len(df_clean['participant_id'].unique())\n",
    "n_trial = len(df_clean['trial_num'].unique())\n",
    "n_conds = len(df_clean['stimuli_presented'].unique())\n",
    "print('Participant_number:', n_subj,'Trial number:', n_trial,'Condition number:', n_conds, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at the practice trials: change e to f\n",
    "practice_tasks = ['f_practiceTrials_s','f_practiceTrials_l']\n",
    "practice_conds = ['f300ms_delay_2_81','f300ms_delay_2_86']\n",
    "df_practice = df[(df['stimuli_presented'].isin(practice_conds)) & (df['trial_template'].isin(practice_tasks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_Accuracy = []\n",
    "Acc_cond = []\n",
    "for sub in subID:\n",
    "    tmpdf = df_practice[df_practice['participant_id'] == sub]\n",
    "    for cond in practice_conds:\n",
    "        tmpAcc = np.mean(tmpdf[tmpdf['stimuli_presented'] == cond]['response_correct'])\n",
    "        Acc_cond.append(tmpAcc)\n",
    "    practice_Accuracy.append((Acc_cond[0] + Acc_cond[-1])/len(practice_conds))\n",
    "    Acc_cond = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpractice_Accuracy = pd.Series(practice_Accuracy, index=df_clean['participant_id'].unique())\n",
    "cat = pd.concat([fpractice_Accuracy,epractice_Accuracy,pd.Series(np.array(env_noise),index=df_clean['participant_id'].unique())],axis = 1, ignore_index=False, names=['Filled','Empty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_cat = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_cat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = []\n",
    "Acc_cond = []\n",
    "Easiest = []\n",
    "Easiest_idx = [6,11] # e300ms_delay_2_81 and e300ms_delay_2_86\n",
    "for sub in subID:\n",
    "    tmpdf = df_clean[df_clean['participant_id'] == sub]\n",
    "    for cond in conds:\n",
    "        tmpAcc = np.mean(tmpdf[tmpdf['stimuli_presented'] == cond]['response_correct'])\n",
    "        Acc_cond.append(tmpAcc)\n",
    "    Easiest.append((Acc_cond[Easiest_idx[0]] + Acc_cond[Easiest_idx[-1]])/len(Easiest_idx)) # average accuracy of 81 and 86 \n",
    "    Accuracy.append(Acc_cond)\n",
    "    Acc_cond = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects who have >= 0 accuracy for the easiest trials: 29\n"
     ]
    }
   ],
   "source": [
    "## Filled duration: Outliers based on the accuracy of the easiest trials \n",
    "Acc_easiest = pd.Series(Easiest, index=df_clean['participant_id'].unique())\n",
    "t = Acc_easiest[Acc_easiest >= threshold]\n",
    "print(\"Subjects who have >=\",threshold, \"accuracy for the easiest trials:\",len(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate the filled and empty\n",
    "Need to rerun the previous codes but change the tasks and conds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eAcc_easiest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-72e30283d3fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fAcc_easiest = Acc_easiest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfAcc_easiest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAcc_easiest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfAcc_easiest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meAcc_easiest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'participant_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Filled'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Empty'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eAcc_easiest' is not defined"
     ]
    }
   ],
   "source": [
    "#fAcc_easiest = Acc_easiest\n",
    "fAcc_easiest = Acc_easiest\n",
    "cat = pd.concat([fAcc_easiest,eAcc_easiest,pd.Series(np.array(env_noise),index=df_clean['participant_id'].unique())],axis = 1, ignore_index=False, names=['Filled','Empty'])\n",
    "cat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check environmental noise and accuracy of the easiest trials \n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat[cat[0]<0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat[cat[1]<0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sample size: 29\n"
     ]
    }
   ],
   "source": [
    "## Exclude the outliers: change fAccuracy, fconds and fAcc_easiest to e-- to see the empty duration \n",
    "df_Accuracy = pd.DataFrame(data = Accuracy, index = subID, columns = conds)\n",
    "Acc_final_sample = df_Accuracy[Acc_easiest >= threshold]\n",
    "Acc_final_sample.head()\n",
    "print('Final sample size:', len(Acc_final_sample))\n",
    "# Acc_final_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Early: 0.5584291187739464\n",
      "Ontime: 0.6063218390804599\n",
      "Late: 0.5706896551724137\n"
     ]
    }
   ],
   "source": [
    "## Early (0:5), ontime(6:11), late (12:-1)\n",
    "early = [np.arange(0,6,1)]\n",
    "ontime = [np.arange(6,11,1)]\n",
    "late = [np.arange(12,17,1)]\n",
    "Acc_early = Acc_final_sample.iloc[:, early[0]].mean(axis = 1)\n",
    "Acc_ontime = Acc_final_sample.iloc[:, ontime[0]].mean(axis = 1)\n",
    "Acc_late = Acc_final_sample.iloc[:, late[0]].mean(axis = 1)\n",
    "print(\"Accuracy\")\n",
    "print(\"Early:\", np.mean(Acc_early))\n",
    "print(\"Ontime:\", np.mean(Acc_ontime))\n",
    "print(\"Late:\",np.mean(Acc_late))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualization: bar plot\n",
    "ACC_plot = pd.DataFrame({'Conditions': conds, 'acc': np.mean(Acc_final_sample, axis = 0)})\n",
    "ax = ACC_plot.plot.bar(rot = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportion short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "resp_short = []\n",
    "resp_short = [True if d == 'Shorter' else False for d in df_clean['response_value']]\n",
    "df_clean['resp_short'] = resp_short\n",
    "PPS = []\n",
    "PPS_cond = []\n",
    "for sub in subID:\n",
    "    tmpdf = df_clean[df_clean['participant_id'] == sub]\n",
    "    for cond in conds:\n",
    "        tmpPPS = np.mean(tmpdf[tmpdf['stimuli_presented'] == cond]['resp_short'])\n",
    "        PPS_cond.append(tmpPPS)\n",
    "    PPS.append(PPS_cond)\n",
    "    PPS_cond = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PPS = pd.DataFrame(data = PPS, index = subID, columns = conds)\n",
    "PPS_final_sample = df_PPS[Acc_easiest >= threshold]\n",
    "# PPS_final_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion short\n",
      "Early: 0.7576628352490421\n",
      "Ontime: 0.5063218390804598\n",
      "Late: 0.38678160919540244\n"
     ]
    }
   ],
   "source": [
    "## Early (0:5), ontime(6:11), late (12:-1)\n",
    "PPS_early = PPS_final_sample.iloc[:, early[0]].mean(axis = 1)\n",
    "PPS_ontime = PPS_final_sample.iloc[:, ontime[0]].mean(axis = 1)\n",
    "PPS_late = PPS_final_sample.iloc[:, late[0]].mean(axis = 1)\n",
    "print(\"Proportion short\")\n",
    "print(\"Early:\", np.mean(PPS_early))\n",
    "print(\"Ontime:\", np.mean(PPS_ontime))\n",
    "print(\"Late:\",np.mean(PPS_late))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualization: bar plot\n",
    "PPS_plot = pd.DataFrame({'Conditions': conds, 'PPS': np.mean(PPS_final_sample, axis = 0)})\n",
    "ePPS_plot = PPS_plot\n",
    "ax = PPS_plot.plot.bar(rot = 0, ylim = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPS_plot.plot(rot = 0,lw=10)\n",
    "plt.plot(np.transpose(PPS_final_sample))\n",
    "plt.xticks(np.arange(0, len(conds), step=1),conds)  # Set label locations.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
